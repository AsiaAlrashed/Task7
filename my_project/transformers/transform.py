import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from mage_ai.data_cleaner.transformer_actions.base import BaseAction
from mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis
from mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action
from pandas import DataFrame

if 'transformer' not in globals():
    from mage_ai.data_preparation.decorators import transformer
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


class TextProcessor:
    def __init__(self, vocab_size=5000, max_length=20, oov_token="<OOV>"):
        self.vocab_size = vocab_size
        self.max_length = max_length
        self.oov_token = oov_token
        self.tokenizer = Tokenizer(num_words=self.vocab_size, oov_token=self.oov_token)
        self.label_encoder = LabelEncoder()

    def fit_tokenizer(self, texts):
        """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù€ Tokenizer Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·"""
        self.tokenizer.fit_on_texts(texts)

    def transform_texts(self, texts):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ø£Ø±Ù‚Ø§Ù… Ù…Ø¹ Ø§Ù„ØªØ¹Ø¨Ø¦Ø©"""
        sequences = self.tokenizer.texts_to_sequences(texts)
        padded_sequences = pad_sequences(sequences, maxlen=self.max_length, padding="post")
        return [list(seq) for seq in padded_sequences]  # ØªØ­ÙˆÙŠÙ„ ndarray Ø¥Ù„Ù‰ list Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø®Ø·Ø£

    def encode_labels(self, labels):
        """ØªØ±Ù…ÙŠØ² Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… ÙƒÙ€ int Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† numpy.integer"""
        return [int(label) for label in self.label_encoder.fit_transform(labels)]


@transformer
def execute_transformer_action(data: tuple, *args, **kwargs) -> tuple:
    """
    ØªÙ†ÙÙŠØ° ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ù„ÙƒÙ„Ø§ Ù…Ø¬Ù…ÙˆØ¹ØªÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `TextProcessor`
    """
    df_train, df_test = data  # Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù† Data Loader

    processor = TextProcessor()

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø­ÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·
    processor.fit_tokenizer(df_train["new_tweet_content"])

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ø£Ø±Ù‚Ø§Ù…
    df_train["processed_text"] = processor.transform_texts(df_train["new_tweet_content"])
    df_test["processed_text"] = processor.transform_texts(df_test["new_tweet_content"])

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
    df_train["encoded_label"] = processor.encode_labels(df_train["Label"])
    df_test["encoded_label"] = processor.encode_labels(df_test["Label"])

    return df_train, df_test


@test
def test_output(output, *args) -> None:
    """
    Ø§Ø®ØªØ¨Ø§Ø± ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„:
    1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù„ÙŠØ³ ÙØ§Ø±ØºÙ‹Ø§
    2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø£Ø´ÙƒØ§Ù„
    3. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© ÙˆÙ„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©
    """
    assert output is not None, "âŒ Ø®Ø·Ø£: Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ (None)"
    assert isinstance(output, tuple), "âŒ Ø®Ø·Ø£: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Tuple (df_train, df_test)"
    assert len(output) == 2, "âŒ Ø®Ø·Ø£: Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ df_train Ùˆ df_test"

    df_train, df_test = output

    for df, name in zip([df_train, df_test], ["df_train", "df_test"]):
        assert isinstance(df, DataFrame), f"âŒ Ø®Ø·Ø£: {name} ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† DataFrame"
        assert "processed_text" in df.columns, f"âŒ Ø®Ø·Ø£: Ø§Ù„Ø¹Ù…ÙˆØ¯ 'processed_text' Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ {name}!"
        assert "encoded_label" in df.columns, f"âŒ Ø®Ø·Ø£: Ø§Ù„Ø¹Ù…ÙˆØ¯ 'encoded_label' Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ {name}!"

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† 'processed_text' Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…
        assert df["processed_text"].apply(lambda x: isinstance(x, list)).all(), f"âŒ Ø®Ø·Ø£: 'processed_text' ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ÙÙŠ {name}!"
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† 'encoded_label' ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø©
        assert df["encoded_label"].apply(lambda x: isinstance(x, int)).all(), f"âŒ Ø®Ø·Ø£: 'encoded_label' ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø© ÙÙŠ {name}!"

    print("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª! Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø¸ÙŠÙØ© ÙˆØ¬Ø§Ù‡Ø²Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ğŸš€")
